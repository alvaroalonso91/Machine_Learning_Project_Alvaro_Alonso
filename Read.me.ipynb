{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Machine Learning Clasificacion binaria \n",
    "\n",
    "Proyecto  de aprendizaje automático para el conjunto de datos **Adult Census Income**.\n",
    "\n",
    "Este conjunto de datos puede encontrarse [aquí](https://www.kaggle.com/datasets/uciml/adult-census-income/data \"aquí\")\n",
    "\n",
    "Below in english.\n",
    "\n",
    "## Autor \n",
    "\n",
    "Hecho por [__Alvaro Alonso Berenguer__](https://github.com/alvaroalonso91/Machine_Learning_Project_Alvaro_Alonso) para el proyecto de aprendizaje automatico(Machine Learning) del bootcamp The Bridge Digital School.\n",
    "\n",
    "\n",
    "## Introducción\n",
    "\n",
    "El objetivo de este trabajo es aplicar diferentes tecnicas y metodos para crear un modelo de aprendizaje automatico eficiente en un problema de clasificacion binario donde el target a predecir esta desbalanceado y conseguir un buen resultado a la hora de predecir datos futuros. Este trabajo se encuentra en el Git Hub indicado divido en 4 entregables, el dataset, una muestra de este, el codigo empleado para este desarrollo y el readme resumen.\n",
    "\n",
    "\n",
    "## Breve descripcion del dataset \n",
    "\n",
    "El dataset es un conjunto de datos censados en Estados Unidos, donde se recogen 15 variables, entre ellas el target(income) que se divide en personas que ganan menos o igual a 50.000 dolares al año y personas que ganan mas de 50.000 dolares al año.\n",
    "Encontramos diferentes variables como la edad, la ocupacion laboral, el sector laboral, el nivel de estudios alcanzado, raza, sexo, pais de origen, etc.\n",
    "\n",
    "\n",
    "\n",
    "## Modelos desarrollados\n",
    "\n",
    "A lo largo del trabajo, se han desarrollado distintos modelos. Analizaremos las ventajas,resultados y el error de cada uno de ellos:\n",
    "\n",
    "  - **Logistic regression**  \n",
    "  - **GaussianNB/ Naive Byers**\n",
    "  - **Random Forest**\n",
    "  - **DecisionTreeClassifier**\n",
    "  - **Support Vector Machine**\n",
    "  - **XGBoost**\n",
    "  - **AdaBoost**\n",
    "\n",
    "## Desarrollo y entrenamiento\n",
    "\n",
    "Tras desarrollar y entrenar cada uno de los modelos, comprobaremos sus resultados, ajustaremos los hiperparametros de los dos modelos que mejor resultado consigan y nos quedaremos con el modelo que mejor se comporte para nuestro problema concreto.\n",
    "\n",
    "## Analisis de errores\n",
    "\n",
    "Por ultimo se mediran la exactitud y la desviacion estandar.\n",
    "\n",
    "------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Machine Learning Project Binary Classification\n",
    "\n",
    "Machine learning project for the data set **Adult Census Income**.\n",
    "\n",
    "This data set can be found [here](https://www.kaggle.com/datasets/uciml/adult-census-income/data \"here\")\n",
    "\n",
    "\n",
    "## Author\n",
    "\n",
    "Made by [__Alvaro Alonso Berenguer__](https://github.com/alvaroalonso91/Machine_Learning_Project_Alvaro_Alonso) for the machine learning project of The Bridge Digital School bootcamp.\n",
    "\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The objective of this work is to apply different techniques and methods to create an efficient machine learning model in a binary classification problem where the target to be predicted is unbalanced and achieve a good result when predicting future data. This work is located in the indicated Git Hub divided into 4 deliverables, the dataset, a sample of it, the code used for this development and the summary readme.\n",
    "\n",
    "\n",
    "## Brief description of the dataset\n",
    "\n",
    "The dataset is a set of data censused in the United States, where 15 variables are collected, including the target (income), which is divided into people who earn less than or equal to 50,000 dollars per year and people who earn more than 50,000 dollars per year. .\n",
    "We find different variables such as age, job occupation, job sector, level of education achieved, race, sex, country of origin, etc.\n",
    "\n",
    "\n",
    "\n",
    "## Developed models\n",
    "\n",
    "Throughout the work, different models have been developed. We will analyze the advantages, results and errors of each of them:\n",
    "\n",
    "  - **Logistic regression**  \n",
    "  - **GaussianNB/ Naive Byers**\n",
    "  - **Random Forest**\n",
    "  - **DecisionTreeClassifier**\n",
    "  - **Support Vector Machine**\n",
    "  - **XGBoost**\n",
    "  - **AdaBoost**\n",
    "\n",
    "## Development and training\n",
    "\n",
    "After developing and training each of the models, we will check their results, we will adjust the hyperparameters of the two models that achieve the best results and we will stay with the model that performs best for our specific problem.\n",
    "\n",
    "## Error analysis\n",
    "\n",
    "Finally, the accuracy and standard deviation will be measured.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
